{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d097db",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\"\n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Twitter Data</h1>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "### ‚òëÔ∏è Objectives\n",
    "At the end of this session, you will be able to:\n",
    "- [ ] Understand how to find and run pre-trained models\n",
    "- [ ] Evaluate results from pre-trained models\n",
    "- [ ] Run a pre-trained model using real twitter data\n",
    "\n",
    "\n",
    "### üî® Pre-Assignment\n",
    "\n",
    "Create a new Conda environment for sentiment anaylsis (sa)\n",
    "\n",
    "```bash\n",
    "  conda create -n sa python=3.8 jupyter -y\n",
    "```\n",
    "\n",
    "Activate your new environment\n",
    "```bash\n",
    "  conda activate sa\n",
    "```\n",
    "\n",
    "Open the jupyter-notebook\n",
    "```bash\n",
    "  jupyter-notebook\n",
    "```\n",
    "\n",
    "Navigate through the repo in the notebook to find `imports.ipynb` for this week and open it.\n",
    "\n",
    "Run all of the cells in the notebook.\n",
    "\n",
    "\n",
    "### Background\n",
    "Please review the weekly narrative [here](https://www.notion.so/Week-2-Data-Centric-AI-the-AI-Product-Lifecycle-72a84c1517b44fcbb3e6bd11d47477dc#2b73937612bb46559f5b91dc2bf55e7d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3934e6e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5ab14",
   "metadata": {},
   "source": [
    "## üöÄ Let's Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea542cb",
   "metadata": {},
   "source": [
    "Let's first start with our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67dcb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv # Allows us to read and write csv files\n",
    "from pprint import pprint # Make our print functions easier to read\n",
    "\n",
    "from transformers import pipeline # |Hugging face pipeline to load online models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4028f",
   "metadata": {},
   "source": [
    "ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n",
    "\n",
    "These models can be applied on:\n",
    "- üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.\n",
    "\n",
    "- üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.\n",
    "- üó£Ô∏è Audio, for tasks like speech recognition and audio classification.\n",
    "\n",
    "This is the pipeline method in transformers that we'll be using to analyze our sentiment data. Since we're not specifying a pretrained model, the pipeline has a default sentiment analysis model called [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3e6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b34b2",
   "metadata": {},
   "source": [
    "In this example, we'll supply two polar sentiments and test out the model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de41c494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998694658279419},\n",
       " {'label': 'NEGATIVE', 'score': 0.994263231754303}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"This is great!\", \"Oh no!\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d04139",
   "metadata": {},
   "source": [
    "The `label` in this case indicates the prediction for the sentiment type.\n",
    "\n",
    "The `score` indicates the confidence of the prediction (between 0 and 1).\n",
    "\n",
    "Since our sentiments were very polar, it was easier for the model to predict the sentiment type.\n",
    "\n",
    "Let's see what happens when we use a less clear example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c077f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9955561757087708},\n",
       " {'label': 'NEGATIVE', 'score': 0.9860844016075134}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenging_sentiments = [\"I don't think freddriq should leave, he's been helpful.\",\n",
    "                          \"Is that the lake we went to last month?\"]\n",
    "sentiment_pipeline(challenging_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b62d4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Loading the Twitter Data\n",
    "\n",
    "Let's play with some twitter data. We'll be using a modified version of the [Elon Musk twitter dataset on Kaggle](https://www.kaggle.com/datasets/andradaolteanu/all-elon-musks-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1a44d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@vincent13031925 For now. Costs are decreasing rapidly.',\n",
      " 'Love this beautiful shot',\n",
      " '@agnostoxxx @CathieDWood @ARKInvest Trust the shrub',\n",
      " 'The art In Cyberpunk is incredible',\n",
      " '@itsALLrisky ü§£ü§£']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/elonmusk_tweets.csv', newline='', encoding='utf8') as f:\n",
    "    tweets=[]\n",
    "    reader = csv.reader(f)\n",
    "    twitter_data = list(reader)\n",
    "    for tweet in twitter_data:\n",
    "        tweets.append(tweet[0])\n",
    "\n",
    "pprint(tweets[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630a8f1",
   "metadata": {},
   "source": [
    "First things first - let's look at the sentiment as determined by the [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) (default model) in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b10279",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_sentiment = sentiment_pipeline(tweets[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ac61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9963656663894653}]\n",
      "@vincent13031925 For now. Costs are decreasing rapidly.\n",
      "\n",
      "[{'label': 'POSITIVE', 'score': 0.9998824596405029}]\n",
      "Love this beautiful shot\n",
      "\n",
      "[{'label': 'NEGATIVE', 'score': 0.8498318791389465}]\n",
      "@agnostoxxx @CathieDWood @ARKInvest Trust the shrub\n",
      "\n",
      "[{'label': 'POSITIVE', 'score': 0.9998857975006104}]\n",
      "The art In Cyberpunk is incredible\n",
      "\n",
      "[{'label': 'NEGATIVE', 'score': 0.9839497208595276}]\n",
      "@itsALLrisky ü§£ü§£\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[:5]:\n",
    "    pprint(sentiment_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3fefd",
   "metadata": {},
   "source": [
    "Let's check out the distribution of positive/negative Tweets and see the breakdown using Python's üêç standard library `collections.Counter`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971a841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 (49.00%) of the tweets classified are positive.\n",
      "51 (51.00%) of the tweets classified are negative.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweet_distro = Counter([x['label'] for x in distil_sentiment])\n",
    "pos_sent_count = tweet_distro['POSITIVE']\n",
    "neg_sent_count = tweet_distro['NEGATIVE']\n",
    "total_sent_count = sum(tweet_distro.values())\n",
    "\n",
    "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
    "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42155a0c",
   "metadata": {},
   "source": [
    "Let's do that process again, but use a model with an additional potential label \"NEUTRAL\" called [bertweet-sentiment-analysis](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis)\n",
    "\n",
    "To start - we'll build a pipeline with the new model by using the ü§ó Hugging Face address: `finiteautomata/bertweet-base-sentiment-analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd6e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet_pipeline = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025127d",
   "metadata": {},
   "source": [
    "Next, and the same as before, let's run the analysis on 100 of Elon's tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5daa650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sentiment = bertweet_pipeline(tweets[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf490693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEU', 'score': 0.9523935317993164}]\n",
      "@vincent13031925 For now. Costs are decreasing rapidly.\n",
      "\n",
      "[{'label': 'POS', 'score': 0.9909942746162415}]\n",
      "Love this beautiful shot\n",
      "\n",
      "[{'label': 'NEU', 'score': 0.9733855128288269}]\n",
      "@agnostoxxx @CathieDWood @ARKInvest Trust the shrub\n",
      "\n",
      "[{'label': 'POS', 'score': 0.9824264049530029}]\n",
      "The art In Cyberpunk is incredible\n",
      "\n",
      "[{'label': 'NEG', 'score': 0.9627320766448975}]\n",
      "@itsALLrisky ü§£ü§£\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[0:5]:\n",
    "    pprint(bertweet_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a316d",
   "metadata": {},
   "source": [
    "And then, let's check out the breakdown of positive, negative, AND neutral sentiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6996cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 (29.00%) of the tweets classified are positive.\n",
      "64 (64.00%) of the tweets classified are neutral.\n",
      "7 (7.00%) of the tweets classified are negative.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweet_distro = Counter([x['label'] for x in bert_sentiment])\n",
    "pos_sent_count = tweet_distro['POS']\n",
    "neu_sent_count = tweet_distro['NEU']\n",
    "neg_sent_count = tweet_distro['NEG']\n",
    "total_sent_count = sum(tweet_distro.values())\n",
    "\n",
    "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
    "print(f\"{neu_sent_count} ({neu_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are neutral.\")\n",
    "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8185798d",
   "metadata": {},
   "source": [
    "‚ùì What do you notice about the difference in the results? \n",
    "\n",
    "Answer -> There is neutral label in the bertweet model. This does move away from binary classification of positive & negative. Hence some of the tweets which are on the edge or boundary are neither classfied as positive or negative but as neutral. Since this model has been specifically trained on tweets, it gets the context associated with it.\n",
    "\n",
    "‚ùì Do the results for the `bertweet-base` model look better, or worse, than the results for the `distilbert-base` model? Why?\n",
    "\n",
    "Answer -> It looks better in context, as those tweets which does not fall into the positive or negative keyword, are classified as neutral. Thereby it is more conservative in classifying the tweets. However the tweets which start with @<user_name> & if that is negative, then it is also classfied as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684f9ae",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Partner Exercise\n",
    "\n",
    "With your partner, try and determine what the following tweets might be classified as. Try to classify them into the same groups as both of the model pipelines we saw today - and try adding a few of your own sentences/Tweets! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc55db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_difficult_tweets = [\n",
    "    \"Kong vs Godzilla has record for most meth ever consumed in a writer's room\",\n",
    "    \"@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\",\n",
    "    \"Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\",\n",
    "    \"Jean-luc bought Twitter\",\n",
    "    \"Elon Musk layoffs 7500 people\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e3837",
   "metadata": {},
   "source": [
    "The `distilbert-base` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fd3d5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.5429081320762634}]\n",
      "Kong vs Godzilla has record for most meth ever consumed in a writer's room\n",
      "\n",
      "[{'label': 'NEGATIVE', 'score': 0.6348376870155334}]\n",
      "@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\n",
      "\n",
      "[{'label': 'POSITIVE', 'score': 0.9419705867767334}]\n",
      "Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\n",
      "\n",
      "[{'label': 'POSITIVE', 'score': 0.9077075123786926}]\n",
      "Jean-luc bought Twitter\n",
      "\n",
      "[{'label': 'NEGATIVE', 'score': 0.9988501071929932}]\n",
      "Elon Musk layoffs 7500 people\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in example_difficult_tweets[0:1000]:\n",
    "    pprint(sentiment_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61230295",
   "metadata": {},
   "source": [
    "The `bertweet-base` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82f2d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEG', 'score': 0.7213028073310852}]\n",
      "Kong vs Godzilla has record for most meth ever consumed in a writer's room\n",
      "\n",
      "[{'label': 'NEU', 'score': 0.8023843765258789}]\n",
      "@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\n",
      "\n",
      "[{'label': 'NEU', 'score': 0.8843539953231812}]\n",
      "Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\n",
      "\n",
      "[{'label': 'NEU', 'score': 0.931235134601593}]\n",
      "Jean-luc bought Twitter\n",
      "\n",
      "[{'label': 'NEU', 'score': 0.735110878944397}]\n",
      "Elon Musk layoffs 7500 people\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in example_difficult_tweets[0:1000]:\n",
    "    pprint(bertweet_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97f2c1c5",
   "metadata": {},
   "source": [
    "‚ùì How did you do? Did you find any surprising results? \n",
    "\n",
    "Answer -> In the first sentence, it was critical of the movie, yet in the base model it was kept as positive, while in bertweet model it was assigned the negative class as being a critical of the movie. There is difference in classifcation in other tweets as well. We tried other tweets as well, by changing the input, found different classfication in different word. One surprising thing, as you put the keyword name person, it recognise it & mark as neutral in the bertweet model.\n",
    "\n",
    "‚ùì Are there any instances where the two models gave different predictions for the same tweet?\n",
    "\n",
    "Answer -> Same as above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv-sa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "58a1f3beba581acd4c6632f9dd5e6882a57b8a8b62de6d2794a3b7b45c88866b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
